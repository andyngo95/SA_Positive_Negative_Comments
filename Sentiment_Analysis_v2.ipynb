{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tf9RNF8535LK"
   },
   "source": [
    "#  Distinguish Positive and Negative Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "bTGgNgPoJonU",
    "outputId": "928d4866-d8a8-443b-82f8-c4cc972a8f42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_submission.csv  test.csv  train.csv  words_list.npy  word_vectors.npy\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "!ls {data_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZSTJ7AG4RweC"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "import tensorflow as tf\n",
    "\n",
    "# Enable Eager Execution\n",
    "tf.enable_eager_execution()\n",
    "tf.executing_eagerly() \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "k2q48NN3U-Ni"
   },
   "source": [
    "## Dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "GPDWEmJabuLs",
    "outputId": "b897c0e9-7211-41b3-9728-b889a77afc1a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14feb4e5</td>\n",
       "      <td>Đến quán 2 lần thôi , rất là thích !\\nQuán tuy...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9c6f6036</td>\n",
       "      <td>Đến quán vào tối chủ_nhật . Có band hát . Khá ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f462cfe</td>\n",
       "      <td>Phục_vụ lâu quá mặc_dù khách rất vắng .\\nĐợi g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>741fd21b</td>\n",
       "      <td>Ko gian bé_tí , quán chật_chội , đông người nê...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5cd6dbbc</td>\n",
       "      <td>Khi mình order , đặt bánh thì nhận được sự tiế...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  class\n",
       "0  14feb4e5  Đến quán 2 lần thôi , rất là thích !\\nQuán tuy...      1\n",
       "1  9c6f6036  Đến quán vào tối chủ_nhật . Có band hát . Khá ...      0\n",
       "2  0f462cfe  Phục_vụ lâu quá mặc_dù khách rất vắng .\\nĐợi g...      0\n",
       "3  741fd21b  Ko gian bé_tí , quán chật_chội , đông người nê...      0\n",
       "4  5cd6dbbc  Khi mình order , đặt bánh thì nhận được sự tiế...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(os.path.join(data_dir, 'train.csv'))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "colab_type": "code",
    "id": "XdR1WTi5GPrK",
    "outputId": "94cb1c19-d1b9-4915-a05b-1846a0e76322"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 13482\n",
      "Positive: 13518\n",
      "Proportion: 1.0 : 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEFCAYAAAAIZiutAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1zool9KOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_count = train_df['class'].value_counts()\n",
    "print('Negative:', class_count[0])\n",
    "print('Positive:', class_count[1])\n",
    "print('Proportion:', round(class_count[0] / class_count[1], 2), ': 1')\n",
    "\n",
    "class_count.plot(kind='bar', title='Count (class)', color=['blue', 'red']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "xnqsFCzGdlfj",
    "outputId": "a3b795de-1ce4-4f74-9a61-44aa02992895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A positive sentence: \n",
      "Phải nói là không đếm được bao_nhiêu lần đã ăn_ở quán này rồi nhưng vẫn kết nổ đĩa . Nhược_điểm là chuyển địa_điểm quá nhiều . Mình đã ăn_ở chỗ LƯ ơng Đình_Của sau đó chuyển sang Phương_Mai , đc một thời_gian lại sang Chùa_Bộc và hôm nọ mới sang chỗ mới nhất_là số 1 Đào_Duy_Anh . Đi tìm quán đến chóng_mặt nhưng vì ăn quen rồi ko sang chỗ khác đc . ăn_ở chỗ khác cứ thấy vị nó không ngon bằng ở đây\n",
      "Về không_gian : Quán hiện_nay 2 tầng . Ngồi trên gác thì chắc là_hơi bí ( mình chưa thử ) . Dưới sân thì rộng , kê được nhiều bàn . Chăng đèn_điện các thứ khá là đẹp_mắt nhg mà lúc khói lên thì cái gì cũng mờ_mờ nhé .\n",
      "Về chất_lượng : Vẫn giữ phong_độ ổn_định , thêm mấy món mới như mực_ống với diềm thăn cả một loại bò thái vuông vuông mà quên xừ tên rồi .\n",
      "Về giá_cả : Ở đây khách đa_số sinh_viên nên giá cũng rất là sinh_viên tầm 100K một người là no . Hôm nào uống rượu thì 120K\n",
      "Về phục_vụ : Cái này hơi kém mà quán cần sửa_chữa , nhân_viên toàn nhỏ nhỏ_con con nên làm hơi chậm , thỉnh_thoảng quên đồ để khách gọi vài lần mới mang ra . Nhg chắc do đông khách nên thôi tạm tha_thứ : ) )\n",
      "Góp_ý là nên tuyển thêm nhân_viên để phục_vụ tốt hơn .\n",
      "\n",
      "A negative sentence: \n",
      "Quán_Bình dân 25k/Tô , nước_lèo nhạt , không đậm mùi bún Huế , vị giông như nước phở vậy . Mình đến quán tầm 9g tối , thịt bò dai , miếng nhỏ , ít . Nói_chung là sẽ ko ghé quán lần nữa .\n",
      "Vị_trí : xa\n",
      "Giá_cả : Bình_dân\n",
      "Chất_lượng : kém\n",
      "Phục_vụ : được\n",
      "Không_gian : được\n"
     ]
    }
   ],
   "source": [
    "print('A positive sentence: ')\n",
    "sample_positive = train_df[train_df['class'] == 1].sample(1)\n",
    "print(sample_positive.loc[sample_positive.index[0], 'text'])\n",
    "\n",
    "print('\\nA negative sentence: ')\n",
    "sample_negative = train_df[train_df['class'] == 0].sample(1)\n",
    "print(sample_negative.loc[sample_negative.index[0], 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "xyygFLLXhWeU",
    "outputId": "d26b18e7-5add-49c3-af2c-2e417886dd39"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3afca6c4</td>\n",
       "      <td>Mình kêu 6 loại khác nhau , mỗi laoij 1 cục mà...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a52dd7db</td>\n",
       "      <td>Ăn ở đây từ trc khi chủ nhà xây nhà mới .   ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a95ec3a0</td>\n",
       "      <td>Các bạn đến ăn ngay và luôn đi nhé ! !\\nMình t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>68c1c84a</td>\n",
       "      <td>Đây gần như quán ruột của mình luôn : ) ) đây ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>627bbd02</td>\n",
       "      <td>Tiếc là 25 năm sống ở Tây Ninh thì đây là lần ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text\n",
       "0  3afca6c4  Mình kêu 6 loại khác nhau , mỗi laoij 1 cục mà...\n",
       "1  a52dd7db  Ăn ở đây từ trc khi chủ nhà xây nhà mới .   ch...\n",
       "2  a95ec3a0  Các bạn đến ăn ngay và luôn đi nhé ! !\\nMình t...\n",
       "3  68c1c84a  Đây gần như quán ruột của mình luôn : ) ) đây ...\n",
       "4  627bbd02  Tiếc là 25 năm sống ở Tây Ninh thì đây là lần ..."
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(os.path.join(data_dir, 'test.csv'))\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rDqkzU_XVCAx"
   },
   "source": [
    "### Load vocabulary and matrix word embedding\n",
    "Fasttext pretrain model: https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.vi.300.vec.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "5e3hSngMUGBZ",
    "outputId": "c04097e4-85d5-46ed-ec7c-3daf4d992d62"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified vocabulary loaded!\n",
      "Word embedding matrix loaded!\n"
     ]
    }
   ],
   "source": [
    "words_list = np.load(os.path.join(data_dir, 'words_list.npy'))\n",
    "print('Simplified vocabulary loaded!')\n",
    "words_list = words_list.tolist()\n",
    "word_vectors = np.load(os.path.join(data_dir, 'word_vectors.npy'))\n",
    "word_vectors = np.float32(word_vectors)\n",
    "print ('Word embedding matrix loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "KLYBgqXyVdcx",
    "outputId": "a45278f5-d232-4ba9-cf65-7cdee27e44e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the vocabulary:  19899\n",
      "Size of the word embedding matrix:  (19899, 300)\n"
     ]
    }
   ],
   "source": [
    "print('Size of the vocabulary: ', len(words_list))\n",
    "print('Size of the word embedding matrix: ', word_vectors.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udbdJlblVp2l"
   },
   "source": [
    "### Get word vector of single word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 884
    },
    "colab_type": "code",
    "id": "bhITygHtVjz7",
    "outputId": "4b537efa-b541-46bb-f8e3-5f13fa1cb54c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index of `ngon` in words_list:  14598\n",
      "Vector representation of `ngon` is:  [-2.040e-02 -9.800e-03  2.290e-01 -3.770e-02  5.430e-02 -2.680e-02\n",
      "  2.190e-02 -6.290e-02 -2.200e-02 -1.010e-02  8.300e-03 -8.810e-02\n",
      " -3.630e-02  7.820e-02 -7.780e-02 -4.930e-02 -6.600e-03 -1.026e-01\n",
      " -1.040e-02  5.380e-02  4.100e-02  6.530e-02 -2.770e-02 -6.340e-02\n",
      "  2.270e-02  4.420e-02  3.340e-02 -4.960e-02  8.290e-02 -3.990e-02\n",
      "  3.750e-02  1.800e-02 -1.115e-01 -7.200e-02 -5.060e-02 -1.051e-01\n",
      " -4.560e-02 -1.765e-01 -3.300e-02 -6.800e-03  5.580e-02 -4.180e-02\n",
      "  4.380e-02  4.940e-02  7.400e-03  4.020e-02 -8.850e-02 -9.840e-02\n",
      " -5.210e-02 -5.500e-03  3.730e-02 -8.460e-02 -6.910e-02 -4.980e-02\n",
      " -3.910e-02 -4.980e-02 -8.690e-02  6.100e-03 -5.360e-02 -3.800e-03\n",
      "  1.162e-01 -4.160e-02  5.000e-03 -7.240e-02 -3.320e-02  1.800e-02\n",
      "  1.200e-02 -4.420e-02  1.350e-01  6.580e-02 -1.110e-02  1.960e-02\n",
      "  1.750e-02  2.010e-02  2.200e-03  1.810e-01 -6.610e-02 -6.860e-02\n",
      " -4.690e-02  7.890e-02  6.880e-02 -5.320e-02  2.770e-02  5.710e-02\n",
      " -1.183e-01  4.170e-02 -8.200e-02 -5.900e-02  8.790e-02  9.640e-02\n",
      "  6.000e-02  1.330e-02 -3.640e-02 -1.110e-02 -2.200e-02  1.770e-02\n",
      " -3.420e-02 -4.020e-02  3.590e-02  1.467e-01 -1.730e-02 -2.650e-02\n",
      "  6.400e-02  7.000e-03 -3.930e-02 -5.540e-02 -4.360e-02  8.000e-02\n",
      " -5.480e-02  3.840e-02 -8.330e-02  7.070e-02 -9.100e-03  2.480e-02\n",
      " -7.500e-03  3.030e-02 -6.600e-03 -9.800e-03  7.640e-02 -9.300e-03\n",
      "  2.330e-02 -2.000e-02  5.970e-02 -2.680e-02 -2.000e-02 -9.700e-03\n",
      " -5.310e-02 -9.820e-02 -2.570e-02  2.400e-02 -5.860e-02  1.820e-02\n",
      " -4.280e-02  9.580e-02  3.400e-02 -7.100e-03 -6.200e-03  1.239e-01\n",
      "  4.830e-02 -4.050e-02  4.810e-02 -1.093e-01  1.540e-02 -3.860e-02\n",
      "  1.250e-01 -7.950e-02  6.800e-03  7.420e-02  5.500e-02 -4.130e-02\n",
      " -2.090e-02 -2.250e-02  3.960e-02 -1.086e-01 -2.200e-02 -4.420e-02\n",
      "  1.965e-01 -2.260e-02  1.196e-01  1.200e-02  1.199e-01 -8.700e-03\n",
      "  4.260e-02  3.460e-02 -3.780e-02  1.951e-01 -9.300e-03 -6.260e-02\n",
      "  2.730e-02  7.340e-02  1.800e-03  5.080e-02 -3.470e-02 -9.680e-02\n",
      " -1.278e-01  3.790e-02  6.920e-02 -5.300e-02 -1.020e-01  1.076e-01\n",
      "  1.361e-01 -7.390e-02  9.650e-02 -2.250e-02  1.597e-01 -2.750e-02\n",
      " -4.200e-03  1.032e-01 -4.910e-02 -7.100e-03 -1.840e-02  7.240e-02\n",
      " -2.040e-02 -5.010e-02 -2.000e-04 -4.190e-02 -5.720e-02 -8.000e-03\n",
      "  9.780e-02 -7.130e-02 -6.070e-02 -1.740e-02 -1.290e-02  8.250e-02\n",
      "  6.600e-03 -2.250e-02 -5.100e-02  6.520e-02 -1.870e-02  5.790e-02\n",
      "  1.814e-01 -1.220e-01  4.770e-02  5.300e-02 -4.230e-02  2.139e-01\n",
      " -9.100e-03  1.314e-01 -3.600e-02 -3.780e-02  4.260e-02  3.000e-04\n",
      " -8.200e-02  1.570e-02 -1.380e-02  3.420e-02 -2.080e-02  1.790e-01\n",
      "  5.240e-02 -1.464e-01  6.330e-02  5.620e-02  2.000e-03 -6.490e-02\n",
      "  4.000e-04 -1.310e-02  1.020e-02  6.380e-02 -1.190e-02  2.440e-02\n",
      " -1.430e-02  1.027e-01  3.200e-03 -1.120e-02  8.270e-02  5.690e-02\n",
      "  2.740e-02 -9.800e-02 -3.150e-02 -9.750e-02 -1.660e-02  7.640e-02\n",
      " -4.960e-02 -7.940e-02  1.177e-01 -2.800e-03  6.860e-02 -5.930e-02\n",
      "  7.470e-02  5.790e-02  3.450e-02  5.550e-02 -3.380e-02  1.292e-01\n",
      "  3.840e-02  7.440e-02 -6.450e-02  2.470e-02 -1.810e-02  9.840e-02\n",
      " -1.329e-01 -6.380e-02 -8.360e-02 -3.580e-02  6.500e-03  8.240e-02\n",
      " -6.140e-02 -1.116e-01  2.310e-02  8.070e-02 -1.670e-02  4.150e-02\n",
      " -8.210e-02  6.290e-02 -5.580e-02  2.600e-03 -2.170e-02  3.200e-03\n",
      " -5.500e-03  6.040e-02  2.990e-02 -1.061e-01  5.200e-02  7.560e-02\n",
      "  6.250e-02  1.007e-01 -1.080e-01 -5.420e-02 -6.620e-02  6.080e-02]\n"
     ]
    }
   ],
   "source": [
    "ngon_idx = words_list.index('ngon')\n",
    "print('Index of `ngon` in words_list: ', ngon_idx)\n",
    "ngon_vec = word_vectors[ngon_idx]\n",
    "print('Vector representation of `ngon` is: ', ngon_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "dXaOWalUNr0G",
    "outputId": "a5f1c746-3fe3-4190-8b4a-894c7b58b090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector representation of `unknow` is:  UNK\n"
     ]
    }
   ],
   "source": [
    "# UNK as unknow word\n",
    "zero_vec = words_list[-1]\n",
    "print('Vector representation of `unknow` is: ', zero_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y_tKqiRGWmYh"
   },
   "source": [
    "### Preprocessing documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t0uANAGcWX59"
   },
   "outputs": [],
   "source": [
    "# Removes punctuation, parentheses, question marks, etc., and leaves only alphanumeric characters\n",
    "import re\n",
    "strip_special_chars = re.compile(\"[^\\w0-9 ]+\")\n",
    "\n",
    "def clean_sentences(string):\n",
    "    string = string.lower().replace(\"<br />\", \" \")\n",
    "    return re.sub(strip_special_chars, \"\", string.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bCH35SwoXDh6"
   },
   "source": [
    "### Transfer comments to word embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MzPjHdRtWWHf"
   },
   "outputs": [],
   "source": [
    "def get_sentence_indices(sentence, max_seq_length, _words_list):\n",
    "    \n",
    "    indices = np.zeros((max_seq_length), dtype='int32')\n",
    "    \n",
    "    # Split sentance to words\n",
    "    words = [word.lower() for word in sentence.split()]\n",
    "    \n",
    "    words = words[:max_seq_length]\n",
    "    for idx, word in enumerate(words):\n",
    "      if(word in _words_list):\n",
    "        indices[idx] = _words_list.index(word)\n",
    "      else:\n",
    "        indices[idx] = len(_words_list)-1\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "O4gNv4udZSn-",
    "outputId": "7b1179ea-788d-45cb-d059-50ef9285501f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10,)\n",
      "Row index for each word:  [  119  8136  4884 18791 16614 15951  3371     0     0     0]\n",
      "Sentence representation of word vectors:\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/embedding_ops.py:132: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(10, 300)\n"
     ]
    }
   ],
   "source": [
    "# Example: Ma trận biểu diễn cho một câu\n",
    "\n",
    "sentence = \"Món này ăn hoài không biết chán\"\n",
    "\n",
    "sentence = clean_sentences(sentence)\n",
    "# Get word index\n",
    "sentence_indices = get_sentence_indices(sentence, max_seq_length=10, _words_list=words_list)\n",
    "\n",
    "print(sentence_indices.shape)\n",
    "print('Row index for each word: ', sentence_indices)\n",
    "\n",
    "print('Sentence representation of word vectors:')\n",
    "print(tf.nn.embedding_lookup(word_vectors,sentence_indices).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwvNkbiqbB3T"
   },
   "source": [
    "### Analysis Train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "kLZQxkJcaVu3",
    "outputId": "5e8fe051-a2cf-4b4a-abae-68d5c857d387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of samples is 27000\n",
      "The total number of words in the files is 2252760\n",
      "The average number of words in the files is 83.43555555555555\n"
     ]
    }
   ],
   "source": [
    "num_words = [len(clean_sentences(x).split()) for x in list(train_df['text'])]\n",
    "print('The total number of samples is', len(train_df))\n",
    "print('The total number of words in the files is', sum(num_words))\n",
    "print('The average number of words in the files is', sum(num_words)/len(num_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "colab_type": "code",
    "id": "C62SMwSvcvAg",
    "outputId": "242b4298-60a6-46a8-c716-2a0aa9f35c7b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZQAAAEKCAYAAAA1qaOTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF7hJREFUeJzt3XuUZlV95vHvI6goEC6KDIvGaRx7\nZNAoNiWXqBOvLYIRJzKKy4kdhwlZa8hEV25CkhGva3BlJigZZdEKik4UUKMw6ARaQLMmS4FuuYOE\nVpvQLdqt3LxkMOBv/ji72teWqnq7+rxV9b58P2vVqnP2udTeUN1P733Ou3eqCkmSdtZjFrsCkqTJ\nYKBIknphoEiSemGgSJJ6YaBIknphoEiSejHSQEmyMclNSa5Psq6V7ZtkbZI72vd9WnmSnJVkQ5Ib\nk6wcuM/qdv4dSVaPss6SpPlZiB7Ki6vqsKqaavunAldU1QrgirYP8EpgRfs6GTgbugACTgeOBI4A\nTp8OIUnS0rEYQ17HA+e37fOB1wyUf7w6XwP2TnIA8ApgbVXdU1X3AmuBYxa60pKk2e064vsXcHmS\nAs6pqjXA/lV1dzv+XWD/tn0gcNfAtZta2UzlvyDJyXQ9G3bffffDDznkkD7bIUkTb/369d+vqv3m\ne/2oA+UFVbU5yVOAtUm+MXiwqqqFzU5rYbUGYGpqqtatW9fHbSXpUSPJnTtz/UiHvKpqc/u+Bfgc\n3TOQ77WhLNr3Le30zcBBA5cva2UzlUuSlpCRBUqS3ZPsOb0NrAJuBi4Bpt/UWg1c3LYvAd7U3vY6\nCri/DY1dBqxKsk97GL+qlUmSlpBRDnntD3wuyfTP+WRV/W2Sa4GLkpwE3Am8rp3/ReBYYAPwE+DN\nAFV1T5J3A9e2895VVfeMsN6SpHnIJE5f7zMUSdpxSdYPfMRjh/lJeUlSLwwUSVIvDBRJUi8MFElS\nLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJUi8M\nFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJ\nUi8MFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvDBRJUi8MFElSLwwUSVIvRh4oSXZJcl2SS9v+wUmu\nTrIhyYVJHtfKH9/2N7TjywfucVorvz3JK0ZdZ0nSjluIHspbgNsG9t8HnFlVTwfuBU5q5ScB97by\nM9t5JDkUOBF4JnAM8KEkuyxAvSVJO2CkgZJkGXAc8JG2H+AlwGfaKecDr2nbx7d92vGXtvOPBy6o\nqger6tvABuCIUdZbkrTjRt1DeT/wJ8DP2v6TgPuq6qG2vwk4sG0fCNwF0I7f387fVv4I12yT5OQk\n65Ks27p1a9/tkCTNYWSBkuRVwJaqWj+qnzGoqtZU1VRVTe23334L8SMlSQN2HeG9nw+8OsmxwG7A\nrwAfAPZOsmvrhSwDNrfzNwMHAZuS7ArsBfxgoHza4DWSpCViZD2UqjqtqpZV1XK6h+pXVtUbgauA\nE9ppq4GL2/YlbZ92/MqqqlZ+YnsL7GBgBXDNqOotSZqfUfZQZvI24IIk7wGuA85t5ecCn0iyAbiH\nLoSoqluSXATcCjwEnFJVDy98tSVJs0nXCZgsU1NTtW7dusWuhiSNlSTrq2pqvtf7SXlJUi8WY8hr\nbCw/9QszHtt4xnELWBNJWvoe9YEyW2hIkobnkJckqRcGiiSpFwaKJKkXBookqRcGiiSpFwaKJKkX\nBookqRcGiiSpFwaKJKkXBookqRcGiiSpFwaKJKkXBookqRcGiiSpFwaKJKkXBookqRcGiiSpFwaK\nJKkXBookqReP+jXl52uuteg3nnHcAtVEkpYGeyiSpF4YKJKkXhgokqReGCiSpF4YKJKkXhgokqRe\nGCiSpF4YKJKkXhgokqReGCiSpF4YKJKkXowsUJLsluSaJDckuSXJO1v5wUmuTrIhyYVJHtfKH9/2\nN7TjywfudVorvz3JK0ZVZ0nS/A0VKEl+dR73fhB4SVU9BzgMOCbJUcD7gDOr6unAvcBJ7fyTgHtb\n+ZntPJIcCpwIPBM4BvhQkl3mUR9J0ggN20P5UOtt/Ockew1zQXV+1HYf274KeAnwmVZ+PvCatn18\n26cdf2mStPILqurBqvo2sAE4Ysh6S5IWyFCBUlUvBN4IHASsT/LJJC+f67okuyS5HtgCrAW+CdxX\nVQ+1UzYBB7btA4G72s97CLgfeNJg+SNcM/izTk6yLsm6rVu3DtMsSVKPhn6GUlV3AH8OvA34deCs\nJN9I8puzXPNwVR0GLKPrVRyyk/WdrX5rqmqqqqb222+/Uf0YSdIMhn2G8uwkZwK30Q1Z/UZV/Zu2\nfeZc11fVfcBVwNHA3kmmF/ZaBmxu25vpekC043sBPxgsf4RrJElLxLA9lL8Cvg48p6pOqaqvA1TV\nd+h6Lb8kyX5J9m7bTwBeThdIVwEntNNWAxe37UvaPu34lVVVrfzE9hbYwcAK4JrhmyhJWgjDLgF8\nHPBPVfUwQJLHALtV1U+q6hMzXHMAcH57I+sxwEVVdWmSW4ELkrwHuA44t51/LvCJJBuAe+je7KKq\nbklyEXAr8BBwynQ9JElLx7CB8iXgZcD0W1tPBC4Hfm2mC6rqRuC5j1D+LR7hLa2q+n/Av5/hXu8F\n3jtkXSVJi2DYIa/dBl4Bpm0/cTRVkiSNo2ED5cdJVk7vJDkc+KfRVEmSNI6GHfJ6K/DpJN8BAvwL\n4PUjq5UkaewMFShVdW2SQ4BntKLbq+qfR1ctSdK4GbaHAvA8YHm7ZmUSqurjI6mVJGnsDBUoST4B\n/CvgemD6ld0CDBRJEjB8D2UKOLR90FCSpF8y7FteN9M9iJck6REN20N5MnBrkmvo1jkBoKpePZJa\nSZLGzrCB8o5RVkKSNP6GfW34K0n+JbCiqr6U5ImAqyZKkrYZdvr636FbRfGcVnQg8PlRVUqSNH6G\nfSh/CvB84AHYttjWU0ZVKUnS+Bn2GcqDVfXTbon3bQtg+QrxLJaf+oUZj20847gFrIkkLYxheyhf\nSfKnwBPaWvKfBv736KolSRo3wwbKqcBW4Cbgd4EvMsNKjZKkR6dh3/L6GfDh9iVJ0i8Zdi6vb/MI\nz0yq6mm910iSNJZ2ZC6vabvRLdW7b//VkSSNq6GeoVTVDwa+NlfV+wFfVZIkbTPskNfKgd3H0PVY\ndmQtFUnShBs2FP7HwPZDwEbgdb3XRpI0toZ9y+vFo66IJGm8DTvk9QezHa+qv+ynOpKkcbUjb3k9\nD7ik7f8GcA1wxygqJUkaP8MGyjJgZVX9ECDJO4AvVNV/GFXFJEnjZdipV/YHfjqw/9NWJkkSMHwP\n5ePANUk+1/ZfA5w/mipJksbRsG95vTfJ/wFe2IreXFXXja5akqRxM+yQF8ATgQeq6gPApiQHj6hO\nkqQxNOwSwKcDbwNOa0WPBf7XqColSRo/w/ZQ/h3wauDHAFX1HWDPUVVKkjR+hg2Un1ZV0aawT7L7\n6KokSRpHwwbKRUnOAfZO8jvAl3CxLUnSgGHf8vrvbS35B4BnAG+vqrUjrZkkaazM2UNJskuSq6pq\nbVX9cVX90TBhkuSgJFcluTXJLUne0sr3TbI2yR3t+z6tPEnOSrIhyY2DU+YnWd3OvyPJ6p1psCRp\nNOYMlKp6GPhZkr128N4PAX9YVYcCRwGnJDkUOBW4oqpWAFe0fYBXAiva18nA2dAFEHA6cCRwBHD6\ndAhJkpaOYT8p/yPgpiRraW96AVTV7890QVXdDdzdtn+Y5DbgQOB44EXttPOBL9O9knw88PH28P9r\nSfZOckA7d21V3QPQ6nAM8Kkh677kLD/1C7Me33iGi2FKGj/DBsrftK95SbIceC5wNbB/CxuA7/Lz\nOcEOBO4auGxTK5upfPufcTJdz4anPvWp862qJGmeZg2UJE+tqn+sqnnP25VkD+CzwFur6oEk245V\nVSWp+d57UFWtAdYATE1N9XJPSdLw5uqhfB5YCZDks1X12h25eZLH0oXJX1fVdA/ne0kOqKq725DW\nlla+GTho4PJlrWwzPx8imy7/8o7UY9zMNiTmcJikpWquh/IZ2H7ajtw4XVfkXOC27VZ0vASYflNr\nNXDxQPmb2tteRwH3t6Gxy4BVSfZpD+NXtTJJ0hIyVw+lZtgexvOB36J7mH99K/tT4Ay6D0qeBNwJ\nvK4d+yJwLLAB+AnwZoCquifJu4Fr23nvmn5AL0laOuYKlOckeYCup/KEtk3br6r6lZkurKr/yy/2\ncAa99BHOL+CUGe51HnDeHHWVJC2iWQOlqnZZqIpIksbbjqyHIknSjAwUSVIvhv1g49ia61PpkqR+\n2EORJPXCQJEk9cJAkST1wkCRJPXCQJEk9cJAkST1wkCRJPXCQJEk9cJAkST1wkCRJPXCQJEk9cJA\nkST1wkCRJPXCQJEk9cJAkST1YuLXQ5k0c63vsvGM4xaoJpL0i+yhSJJ6YaBIknphoEiSemGgSJJ6\nYaBIknphoEiSemGgSJJ6YaBIknphoEiSemGgSJJ6YaBIknrhXF4TZra5vpznS9Io2UORJPXCQJEk\n9WJkgZLkvCRbktw8ULZvkrVJ7mjf92nlSXJWkg1JbkyycuCa1e38O5KsHlV9JUk7Z5Q9lI8Bx2xX\ndipwRVWtAK5o+wCvBFa0r5OBs6ELIOB04EjgCOD06RCSJC0tIwuUqvo74J7tio8Hzm/b5wOvGSj/\neHW+Buyd5ADgFcDaqrqnqu4F1vLLISVJWgIW+hnK/lV1d9v+LrB/2z4QuGvgvE2tbKbyX5Lk5CTr\nkqzbunVrv7WWJM1p0V4brqpKUj3ebw2wBmBqaqq3+04SXymWNEoL3UP5XhvKon3f0so3AwcNnLes\nlc1ULklaYhY6UC4Bpt/UWg1cPFD+pva211HA/W1o7DJgVZJ92sP4Va1MkrTEjGzIK8mngBcBT06y\nie5trTOAi5KcBNwJvK6d/kXgWGAD8BPgzQBVdU+SdwPXtvPeVVXbP+iXJC0BIwuUqnrDDIde+gjn\nFnDKDPc5Dzivx6pJkkbAT8pLknphoEiSemGgSJJ6YaBIknphoEiSemGgSJJ6YaBIknrhEsACZp/n\nC5zrS9Lc7KFIknphoEiSemGgSJJ6YaBIknphoEiSeuFbXhqKqz1Kmos9FElSLwwUSVIvHPLSTvND\nkZLAHookqScGiiSpFwaKJKkXBookqRcGiiSpF77lpZHzQ5HSo4M9FElSLwwUSVIvHPLSoprrQ5Gz\ncbhMWlrsoUiSemGgSJJ6YaBIknrhMxSNLSellJYWA0UTy8+/SAvLQNGjkmEj9c9nKJKkXthDkXaQ\nvRvpkRko0nZ25sOWflBTj2ZjEyhJjgE+AOwCfKSqzljkKkm98q01jbuxCJQkuwAfBF4ObAKuTXJJ\nVd26uDWTFs7O9H7myxDTjhiLQAGOADZU1bcAklwAHA8YKNIILUaIjdJcATmqIcud6X2OU881VbXY\ndZhTkhOAY6rqP7X93wKOrKrfGzjnZODktvss4OYFr+jCeTLw/cWuxAjZvvE2ye2b5LYBPKOq9pzv\nxePSQ5lTVa0B1gAkWVdVU4tcpZGxfePN9o2vSW4bdO3bmevH5XMom4GDBvaXtTJJ0hIxLoFyLbAi\nycFJHgecCFyyyHWSJA0YiyGvqnooye8Bl9G9NnxeVd0yyyVrFqZmi8b2jTfbN74muW2wk+0bi4fy\nkqSlb1yGvCRJS5yBIknqxcQFSpJjktyeZEOSUxe7PvOR5LwkW5LcPFC2b5K1Se5o3/dp5UlyVmvv\njUlWLl7N55bkoCRXJbk1yS1J3tLKJ6V9uyW5JskNrX3vbOUHJ7m6tePC9nIJSR7f9je048sXs/7D\nSrJLkuuSXNr2J6Z9STYmuSnJ9dOv0U7Q7+feST6T5BtJbktydJ9tm6hAGZii5ZXAocAbkhy6uLWa\nl48Bx2xXdipwRVWtAK5o+9C1dUX7Ohk4e4HqOF8PAX9YVYcCRwGntP9Hk9K+B4GXVNVzgMOAY5Ic\nBbwPOLOqng7cC5zUzj8JuLeVn9nOGwdvAW4b2J+09r24qg4b+MzJpPx+fgD426o6BHgO3f/D/tpW\nVRPzBRwNXDawfxpw2mLXa55tWQ7cPLB/O3BA2z4AuL1tnwO84ZHOG4cv4GK6Odomrn3AE4GvA0fS\nfbp611a+7feU7s3Fo9v2ru28LHbd52jXsvYXz0uAS4FMWPs2Ak/ermzsfz+BvYBvb//fv8+2TVQP\nBTgQuGtgf1MrmwT7V9Xdbfu7wP5te2zb3IY/ngtczQS1rw0HXQ9sAdYC3wTuq6qH2imDbdjWvnb8\nfuBJC1vjHfZ+4E+An7X9JzFZ7Svg8iTr25ROMBm/nwcDW4GPtuHKjyTZnR7bNmmB8qhQ3T8Xxvp9\n7yR7AJ8F3lpVDwweG/f2VdXDVXUY3b/kjwAOWeQq9SbJq4AtVbV+sesyQi+oqpV0Qz6nJPm3gwfH\n+PdzV2AlcHZVPRf4MT8f3gJ2vm2TFiiTPEXL95IcANC+b2nlY9fmJI+lC5O/rqq/acUT075pVXUf\ncBXdENDeSaY/SDzYhm3ta8f3An6wwFXdEc8HXp1kI3AB3bDXB5ic9lFVm9v3LcDn6P5RMAm/n5uA\nTVV1ddv/DF3A9Na2SQuUSZ6i5RJgddteTffsYbr8Te2NjKOA+we6r0tOkgDnArdV1V8OHJqU9u2X\nZO+2/QS650O30QXLCe207ds33e4TgCvbvxKXpKo6raqWVdVyuj9fV1bVG5mQ9iXZPcme09vAKrqZ\ny8f+97OqvgvcleQZreildEuA9Ne2xX5QNIIHT8cC/0A3bv1ni12febbhU8DdwD/T/aviJLpx5yuA\nO4AvAfu2c0P3Zts3gZuAqcWu/xxtewFdl/pG4Pr2dewEte/ZwHWtfTcDb2/lTwOuATYAnwYe38p3\na/sb2vGnLXYbdqCtLwIunaT2tXbc0L5umf47ZIJ+Pw8D1rXfz88D+/TZNqdekST1YtKGvCRJi8RA\nkST1wkCRJPXCQJEk9cJAkST1wkDRREjyZ2123xvbLLFHLnaddkaSjyU5Ye4z533/w5IcO7D/jiR/\nNKqfp0eHsVgCWJpNkqOBVwErq+rBJE8GHrfI1VrqDgOmgC8udkU0OeyhaBIcAHy/qh4EqKrvV9V3\nAJIcnuQrbaK/ywammDg83ZolNyT5i7S1Z5L8dpL/OX3jJJcmeVHbXpXkq0m+nuTTbT6y6fUz3tnK\nb0pySCvfI8lHW9mNSV47232GkeSPk1zb7je91srydGtbfLj10i5vn9InyfMGem1/keTmNovEu4DX\nt/LXt9sfmuTLSb6V5Pfn/X9Dj1oGiibB5cBBSf4hyYeS/DpsmzPsr4ATqupw4Dzgve2ajwL/pbp1\nS+bUej1/DrysuokD1wF/MHDK91v52cD00NF/pZuu4ler6tnAlUPcZ7Y6rKJbm+IIuh7G4QMTF64A\nPlhVzwTuA1470M7frW6yyocBquqnwNuBC6tb8+PCdu4hwCva/U9v//2koTnkpbFXVT9KcjjwQuDF\nwIXpVutcBzwLWNtNIcYuwN1trq29q+rv2i0+QTez7GyOolu07e/bvR4HfHXg+PQkl+uB32zbL6Ob\n72q6nvemm613tvvMZlX7uq7t70EXJP8IfLuqrh+ow/LWzj2ravr+n6QbGpzJF1ov78EkW+imMd80\nZN0kA0WToaoeBr4MfDnJTXST3K0HbqmqowfPnZ68cQYP8Ys9992mLwPWVtUbZrjuwfb9YWb/czXX\nfWYT4L9V1Tm/UNitK/PgQNHDwBPmcf/t7+HfD9ohDnlp7CV5RpIVA0WHAXfSrTC3X3toT5LHJnlm\nddPK35fkBe38Nw5cuxE4LMljkhxEN/wD8DXg+Ume3u61e5J/PUfV1gKnDNRzn3neZ9plwH8ceHZz\nYJKnzHRya+cPB954O3Hg8A+BPYf8udJQDBRNgj2A85PcmuRGuiGld7RnBScA70tyA93Mxr/Wrnkz\n8MF0Kytm4F5/T7dM6q3AWXRL+FJVW4HfBj7VfsZXmXvhrPcA+7QH4TfQrVO+I/c5J8mm9vXVqrqc\nbtjqq60X9hnmDoWTgA+3du5Ot2IidNPNH7rdQ3lppzjbsB712pDRpVX1rEWuSu+S7FFVP2rbp9Kt\nCf6WRa6WJpRjpNJkOy7JaXR/1u+k6x1JI2EPRZLUC5+hSJJ6YaBIknphoEiSemGgSJJ6YaBIknrx\n/wG6a9TJo7v9ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(num_words, 100)\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axis([0, 600, 0, 5000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GeIifGzCdDBs"
   },
   "source": [
    "Follow histogram we select MAX_SEQ_LENGTH is 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MLa3ZhQdBNY"
   },
   "outputs": [],
   "source": [
    "MAX_SEQ_LENGTH = 200"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGJSIDQydwjD"
   },
   "source": [
    "### Change words to matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mLHgPdOHdVBM"
   },
   "outputs": [],
   "source": [
    "def text2ids(df, max_length, _word_list):\n",
    "    \"\"\"\n",
    "    Change text to id in matrix\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df: DataFrame\n",
    "    max_length: int\n",
    "    _word_list: numpy.array\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    numpy.array\n",
    "        len(df) x max_length contains indices of text\n",
    "    \"\"\"\n",
    "    ids = np.zeros((len(df), max_length), dtype='int32')\n",
    "    for idx, text in enumerate(tqdm(df['text'])):\n",
    "        ids[idx,:] = get_sentence_indices(clean_sentences(text), max_length, _word_list)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "uQpKnc3jMqNa",
    "outputId": "cac9725c-25ec-4023-b106-f9cfb538fd6a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/27000 [00:00<06:59, 64.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting train_df...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27000/27000 [08:37<00:00, 52.16it/s]\n"
     ]
    }
   ],
   "source": [
    "print(\"Converting train_df...\")\n",
    "train_ids = text2ids(train_df, MAX_SEQ_LENGTH, words_list)\n",
    "np.save('train_ids.npy', train_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4fdCtmneNqZw"
   },
   "outputs": [],
   "source": [
    "# Trường hợp đã tính toán và lưu ma trận rồi thì ta có thể load lên\n",
    "train_ids = np.load('train_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "jk-esTk0OO5p",
    "outputId": "04dd7754-bd43-4f7b-de25-5edbb7863ea4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word indexes of the first review:  [10774 11975  4826  7446  6880 10642  5767 18584 11975  7090  5284  8591\n",
      " 15213 18109 10642 11022  4690 11975 16032 10630  2465 14595  2750  8231\n",
      "  2563 10627  7733  9133  3513 19798  2876 10627  1047 12844 13512  7555\n",
      " 14312 13245  3961   376 19772 15253 16614 17330 17016 10642 14598 15341\n",
      "  3913 19519  9334 15522 13952 13245  5596 15221 12109 14341 14017   556\n",
      " 17115 19151 18839 10346  9076 18584 11975  3364     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print('Word indexes of the first review: ', train_ids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tISghUyN04cb"
   },
   "outputs": [],
   "source": [
    "vocab_size = train_ids.max() + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1h6E82p0PiLn"
   },
   "source": [
    "### Split into train, validation và test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B2-eOZfKPrjo"
   },
   "source": [
    "**train : validation : test = 0.8 : 0.1 : 0.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MoBzDNS6PqBH"
   },
   "outputs": [],
   "source": [
    "train_x, test_validation_x, train_y, test_validation_y  = train_test_split(train_ids, train_df['class'], test_size=0.2, random_state=2019)\n",
    "validation_x, test_x, validation_y, test_y = train_test_split(test_validation_x, test_validation_y, test_size=0.5, random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YhSxr4r7Qi92"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DQTvO7lcQQ3C"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x,train_y)).batch(batch_size=BATCH_SIZE)\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_x,validation_y)).batch(batch_size=BATCH_SIZE)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_x,test_y)).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "o1mQPWZnRy08",
    "outputId": "e1ed0cee-4125-49d1-ab08-33400904af41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[12844  5596  4884 ...     0     0     0]\n",
      " [10774 16521 13952 ...     0     0     0]\n",
      " [ 7446 10698 10774 ...     0     0     0]\n",
      " ...\n",
      " [ 4884 16995  4601 ...     0     0     0]\n",
      " [ 3913 15085 14017 ...     0     0     0]\n",
      " [ 4788 14598   310 ...     0     0     0]], shape=(256, 200), dtype=int32)\n",
      "Total:  84\n"
     ]
    }
   ],
   "source": [
    "for idx, (x,y) in enumerate(train_dataset):\n",
    "    if idx == 0:\n",
    "        print(x)\n",
    "print(\"Total: \", idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "w2P5l-EF0ao6",
    "outputId": "242c4be7-d839-488e-b672-20aa0566e55b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19899"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aQP1QMcKT0Kf"
   },
   "source": [
    "## Build RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X2h7lPbXY-1R"
   },
   "source": [
    "### Create LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUZZ4d5nTIp4"
   },
   "outputs": [],
   "source": [
    "if tf.test.is_gpu_available():\n",
    "    lstm_layer = tf.keras.layers.CuDNNLSTM\n",
    "else:\n",
    "    import functools\n",
    "    lstm_layer = functools.partial(\n",
    "            tf.keras.layers.LSTM, recurrent_activation='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOuW1nfSdXVW"
   },
   "outputs": [],
   "source": [
    "class BahdanauAttention(tf.keras.Model):\n",
    "    def __init__(self, units):\n",
    "        super(BahdanauAttention, self).__init__()\n",
    "        self.W1 = tf.keras.layers.Dense(units)\n",
    "        self.W2 = tf.keras.layers.Dense(units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, values):\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # we are doing this to perform addition to calculate the score\n",
    "        \n",
    "        #hidden_with_time_axis = tf.expand_dims(query, 1)\n",
    "\n",
    "        # score shape == (batch_size, max_length, hidden_size)\n",
    "        score = self.V(tf.nn.tanh(self.W1(values))) #+ self.W2(hidden_with_time_axis)))\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        # we get 1 at the last axis because we are applying score to self.V\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # context_vector shape after sum == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * values\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "\n",
    "        return context_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2a3sSbPxfuD0"
   },
   "outputs": [],
   "source": [
    "LSTM_UNITS = 128\n",
    "N_LAYERS = 2\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyzHuj74WieK"
   },
   "outputs": [],
   "source": [
    "class SentimentAnalysisModel(tf.keras.Model):\n",
    "    def __init__(self, word2vec, lstm_units, n_layers, num_classes, dropout_rate=0.4):\n",
    "        super().__init__(name='sentiment_analysis')\n",
    "        self.word2vec = word2vec\n",
    "        \n",
    "        self.lstm_layers = [] # LSTM layer\n",
    "        self.dropout_layers = [] # dropout layer\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            self.lstm_layers.append(lstm_layer(lstm_units, return_sequences=True))\n",
    "            self.dropout_layers.append(tf.keras.layers.Dropout(dropout_rate))\n",
    "            \n",
    "        self.dense_layer = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        self.dense2 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.dropout = tf.keras.layers.Dropout(0.5)\n",
    "        self.attention = BahdanauAttention(lstm_units)\n",
    "        ### END CODE HERE\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = inputs\n",
    "        out = tf.nn.embedding_lookup(self.word2vec, out)\n",
    "        for i in range(len(self.lstm_layers)):\n",
    "            out = self.lstm_layers[i](out)\n",
    "            out = self.dropout_layers[i](out)\n",
    "        out = self.attention(out)\n",
    "        out = self.dense2(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.dense_layer(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F-utq8BZu76K"
   },
   "outputs": [],
   "source": [
    "class CNNModel(tf.keras.Model):\n",
    "    def __init__(self, word2vec, num_classes, dropout_rate=0.2):\n",
    "        super().__init__(name='CNNModel')\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, 300, \n",
    "                           weights=[word2vec], \n",
    "                           input_length=MAX_SEQ_LENGTH, \n",
    "                           trainable=True)\n",
    "        \n",
    "        self.conv1D = tf.keras.layers.Conv1D(256, 3, activation='relu')\n",
    "        self.conv1D2 = tf.keras.layers.Conv1D(64, 3, activation='relu')\n",
    "        self.pool = tf.keras.layers.GlobalMaxPool1D()\n",
    "        self.dense1 = tf.keras.layers.Dense(256, activation='relu')\n",
    "        self.softmax = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "        \n",
    "        self.flattern = tf.keras.layers.Flatten()\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
    "        self.sdropout = tf.keras.layers.SpatialDropout1D(0.2)\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        out = inputs\n",
    "        out = self.embedding(out)\n",
    "        out = self.sdropout(out)\n",
    "        out = self.conv1D(out)\n",
    "        out = self.pool(out)\n",
    "        out = self.dense1(out)\n",
    "        out = self.dropout(out)\n",
    "        out = self.softmax(out)\n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RVrxaBOujZTB"
   },
   "source": [
    "Khởi tạo mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNJgl7bAfqaq"
   },
   "outputs": [],
   "source": [
    "#model = SentimentAnalysisModel(word_vectors, LSTM_UNITS, N_LAYERS, NUM_CLASSES)\n",
    "model = CNNModel(word_vectors, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZzK2Yuk_bUiu"
   },
   "outputs": [],
   "source": [
    "model2 = SentimentAnalysisModel(word_vectors, LSTM_UNITS, N_LAYERS, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7IUyoz7Mmi36"
   },
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTCY-93vL1ur"
   },
   "source": [
    "Train parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kVHRXfewLwFv"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "EPOCHS = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Jx1pYLwDv5sD"
   },
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nuTf-CggedXf"
   },
   "outputs": [],
   "source": [
    "global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "checkpoint_dir = './model'\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ApouuAjoPIuy"
   },
   "outputs": [],
   "source": [
    "from fastprogress import master_bar, progress_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Uat4rr_ONBpL"
   },
   "outputs": [],
   "source": [
    "def epoch_training(model, dataset, global_step, mb, num_step):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        mean loss of a epoch\n",
    "    \"\"\"\n",
    "    train_losses = [] \n",
    "    val_gt = []\n",
    "    val_pred = [] \n",
    "    dataset_iter = iter(dataset)\n",
    "    for _ in progress_bar(range(num_step), parent=mb):\n",
    "        inp, target = next(dataset_iter)\n",
    "        val_gt.extend(target.numpy().astype(np.int32).tolist())\n",
    "        with tf.GradientTape() as tape:\n",
    "            # Feedforward\n",
    "            predictions = model(inp)\n",
    "            loss = tf.losses.sparse_softmax_cross_entropy(target, predictions) # sparse_softmax_cross_entropy\n",
    "            train_losses.append(loss) # Add loss into list train_losses\n",
    "        \n",
    "        # gradient between loss and model\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        # Optimize weights depend on gradient\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables), global_step=global_step)\n",
    "\n",
    "        val_pred.extend(tf.argmax(predictions,1).numpy().astype(np.int32).tolist())\n",
    "        mb.child.comment = 'Train loss {:.4f}'.format(loss)\n",
    "    return sum(train_losses)/ len(train_losses), f1_score(val_gt, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2XiNIW2mWYzo"
   },
   "outputs": [],
   "source": [
    "def epoch_evaluation(model, dataset, mb, num_step):\n",
    "    \n",
    "    val_losses = [] \n",
    "    val_gt = [] \n",
    "    val_pred = []\n",
    "    dataset_iter = iter(dataset)\n",
    "    for _ in progress_bar(range(num_step), parent=mb):\n",
    "        inp, target = next(dataset_iter)\n",
    "        \n",
    "        val_gt.extend(target.numpy().astype(np.int32).tolist())\n",
    "        \n",
    "        # Feed forward\n",
    "        predictions = model(inp)\n",
    "        \n",
    "        loss = tf.losses.sparse_softmax_cross_entropy(target, predictions)\n",
    "        \n",
    "        val_losses.append(loss)\n",
    "        \n",
    "        val_pred.extend(tf.argmax(predictions,1).numpy().astype(np.int32).tolist())\n",
    "        \n",
    "        mb.child.comment = 'Validation loss {:.4f}'.format(loss)\n",
    "        \n",
    "    return (sum(val_losses)/ len(val_losses)), f1_score(val_gt, val_pred), precision_score(val_gt, val_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2rLv98h_ZMcF"
   },
   "outputs": [],
   "source": [
    "best_score = 0\n",
    "mb = master_bar(range(EPOCHS))\n",
    "mb.names = ['Training loss', 'Validation loss', 'F1']\n",
    "training_losses = []\n",
    "validation_losses = []\n",
    "f1_scores = []\n",
    "x = []\n",
    "\n",
    "train_step = math.ceil(len(train_x)*1.0/BATCH_SIZE)\n",
    "val_step = math.ceil(len(validation_x)*1.0/BATCH_SIZE)\n",
    "for epoch in mb:\n",
    "    \n",
    "    # initializing the hidden state at the start of every epoch\n",
    "    # initally hidden is None\n",
    "    hidden = model.reset_states()\n",
    "    x.append(epoch)\n",
    "    \n",
    "    # Training\n",
    "    training_loss, train_score = epoch_training(model, train_dataset, global_step, mb, train_step)\n",
    "    \n",
    "    mb.write('Finish train epoch {} with loss {:.4f}'.format(epoch, training_loss))\n",
    "    training_losses.append(training_loss)\n",
    "    \n",
    "    # Validating\n",
    "    valid_loss, valid_score, pre_score = epoch_evaluation(model, validation_dataset, mb, val_step)\n",
    "    mb.write('Finish validate epoch {} with loss {:.4f} f1_score {:.4f} precision {:.4f}'.format(epoch,valid_loss, valid_score, pre_score))\n",
    "    validation_losses.append(valid_loss)\n",
    "    f1_scores.append(valid_score)\n",
    "    \n",
    "    global_step.assign_add(1)\n",
    "    mb.update_graph([[x, training_losses], [x, validation_losses], [x, f1_scores]], [0,EPOCHS], [0,1])\n",
    "    \n",
    "    if best_score < valid_score:\n",
    "        mb.write(\"Improved f1-score from {:.4f} to {:.4f}\".format(best_score, valid_score))\n",
    "        \n",
    "        best_score = valid_score\n",
    "\n",
    "        model.save_weights('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fApzh14xhVWg"
   },
   "source": [
    "### Valid on testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oo5TtZdhmXOV"
   },
   "outputs": [],
   "source": [
    "#model.load_weights(checkpoint_prefix)\n",
    "model.load_weights('model_cnn.h5')\n",
    "test_loss, test_score,_ = epoch_evaluation(model, test_dataset, mb, math.ceil(len(test_x)*1.0/BATCH_SIZE))\n",
    "print(\"F1-score on test set:\", test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "v8iQ-HqwiHgZ"
   },
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462
    },
    "colab_type": "code",
    "id": "SLSHFoEc_y1Z",
    "outputId": "84067bc0-3984-45c6-9e90-5909f525bd3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting underthesea\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d0/e6/820172617b4d000d1b44d61287bff06249d36fcf2dabfd76c7fe0aca16de/underthesea-1.1.15-py3-none-any.whl (11.3MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3MB 29.9MB/s \n",
      "\u001b[?25hCollecting nltk==3.4 (from underthesea)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/ed/9c755d357d33bc1931e157f537721efb5b88d2c583fe593cc09603076cc3/nltk-3.4.zip (1.4MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4MB 57.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: Click>=6.0 in /usr/local/lib/python3.6/dist-packages (from underthesea) (7.0)\n",
      "Collecting python-crfsuite==0.9.6 (from underthesea)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2f/86/cfcd71edca9d25d3d331209a20f6314b6f3f134c29478f90559cee9ce091/python_crfsuite-0.9.6-cp36-cp36m-manylinux1_x86_64.whl (754kB)\n",
      "\u001b[K     |████████████████████████████████| 757kB 51.6MB/s \n",
      "\u001b[?25hCollecting languageflow==1.1.9a1 (from underthesea)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0c/f3/de81863dff39df3dbb7be8fa7e8135beddd64e6e46a6f140c9484b357cc7/languageflow-1.1.9a1-py2.py3-none-any.whl (416kB)\n",
      "\u001b[K     |████████████████████████████████| 419kB 57.5MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk==3.4->underthesea) (1.12.0)\n",
      "Collecting singledispatch (from nltk==3.4->underthesea)\n",
      "  Downloading https://files.pythonhosted.org/packages/c5/10/369f50bcd4621b263927b0a1519987a04383d4a98fb10438042ad410cf88/singledispatch-3.4.0.3-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: nltk\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Stored in directory: /root/.cache/pip/wheels/4b/c8/24/b2343664bcceb7147efeb21c0b23703a05b23fcfeaceaa2a1e\n",
      "Successfully built nltk\n",
      "Installing collected packages: singledispatch, nltk, python-crfsuite, languageflow, underthesea\n",
      "  Found existing installation: nltk 3.2.5\n",
      "    Uninstalling nltk-3.2.5:\n",
      "      Successfully uninstalled nltk-3.2.5\n",
      "Successfully installed languageflow-1.1.9a1 nltk-3.4 python-crfsuite-0.9.6 singledispatch-3.4.0.3 underthesea-1.1.15\n"
     ]
    }
   ],
   "source": [
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NtTkXJLi8P-t"
   },
   "outputs": [],
   "source": [
    "from underthesea import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nGAD6lANiSQA"
   },
   "outputs": [],
   "source": [
    "def predict(sentence, model, _word_list=words_list, _max_seq_length=MAX_SEQ_LENGTH):\n",
    "    \n",
    "    sentence = word_tokenize(sentence, format=\"text\")\n",
    "    sentence = clean_sentences(sentence)\n",
    "    \n",
    "    sentence_indices = get_sentence_indices(sentence, max_seq_length=_max_seq_length, _words_list=_word_list)\n",
    "    pred = model(sentence_indices.reshape((1,_max_seq_length)))\n",
    "    return tf.argmax(pred,1).numpy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7I51eWDBRT07"
   },
   "outputs": [],
   "source": [
    "model.load_weights('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "jFlqeP31RUeG",
    "outputId": "a2ece361-3d78-4190-e1b8-7372c5fdaba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: [0]\n",
      "Test 2: [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test 1:\",predict(\"Quán này rất dở\", model))\n",
    "print(\"Test 2:\",predict(\"Quán này rất ngon\", model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o1ub02WuiZ8f"
   },
   "outputs": [],
   "source": [
    "# Combine 2 model\n",
    "def predict2(sentence, model1, model2, _word_list=words_list, _max_seq_length=MAX_SEQ_LENGTH):\n",
    "    \n",
    "    sentence = word_tokenize(sentence, format=\"text\")\n",
    "    sentence = clean_sentences(sentence)\n",
    "    \n",
    "    sentence_indices = get_sentence_indices(sentence, max_seq_length=_max_seq_length, _words_list=_word_list)\n",
    "    pred1 = model1(sentence_indices.reshape((1,_max_seq_length)))\n",
    "    pred2 = model2(sentence_indices.reshape((1,_max_seq_length)))\n",
    "    final_pred = np.concatenate([pred1,pred2], axis=1)\n",
    "    return tf.argmax(final_pred, 1).numpy() % 2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BHVSEPHNlsUf"
   },
   "outputs": [],
   "source": [
    "#model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.load_weights('model_cnn.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TDT0YbAgMhc_"
   },
   "outputs": [],
   "source": [
    "model2.load_weights('model_lstm.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "Qrq7QAY9maNR",
    "outputId": "4ee0320c-ad33-4e83-dfee-c9e34ed3f47a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: [0]\n",
      "Test 2: [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test 1:\",predict2(\"Quán này rất dở\", model, model2))\n",
    "print(\"Test 2:\",predict2(\"Quán này rất ngon\", model, model2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "utKwdYdxmf9o",
    "outputId": "3ce32983-7de4-437b-dd46-af129ba69255"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3afca6c4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a52dd7db</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>a95ec3a0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68c1c84a</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>627bbd02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          class\n",
       "id             \n",
       "3afca6c4      0\n",
       "a52dd7db      0\n",
       "a95ec3a0      0\n",
       "68c1c84a      0\n",
       "627bbd02      0"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.read_csv(data_dir+\"/sample.csv\", index_col=0)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1071
    },
    "colab_type": "code",
    "id": "gREqlAwlSQrT",
    "outputId": "a45898ff-cbfb-43fb-cfca-3a0c771a55d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Mình kêu 6 loại khác nhau , mỗi laoij 1 cục mà...\n",
       "1       Ăn ở đây từ trc khi chủ nhà xây nhà mới .   ch...\n",
       "2       Các bạn đến ăn ngay và luôn đi nhé ! !\\nMình t...\n",
       "3       Đây gần như quán ruột của mình luôn : ) ) đây ...\n",
       "4       Tiếc là 25 năm sống ở Tây Ninh thì đây là lần ...\n",
       "5       Vâ ̃ n la ̀ Ze ́ , Ze ́ luôn nhâ ́ t 👍\\nCuô ́ ...\n",
       "6       Nhà hàng đẹp , không gian rộng , có phòng riên...\n",
       "7       Vừa rồi có ghé ăn tiêp , mình chọn món cơm cá ...\n",
       "8       Quán này bánh nhiều + ngon cực\\nThích nhất là ...\n",
       "9       Đến với Wichita lúc đầy là về tarot nhưng tron...\n",
       "10      Nói chung ở quán này ăn đồ nướng là bá cháy , ...\n",
       "11      Điều đầu tiên mà mình thích ở Bamboo Dimsum là...\n",
       "12      Đồ uống order đi bị ít hơn so với uống ở đó . ...\n",
       "13      Quán nhỏ à , đặt được có hai bàn , cô chú rất ...\n",
       "14      Quán với không gian rất Việt Nam , vừa có chút...\n",
       "15      Đi đây cũng lâu rồi . Dịp sự kiện tiger . h ch...\n",
       "16      Quán mới mở , view đẹp , nước uống có ly đẹp ,...\n",
       "17      Hôm nay mình đi chơi về tầm 9h tối , sẵn có ph...\n",
       "18      Súp 15k đầy ấp ghẹ . . Tôm Hỏa tiễn có 5k mà q...\n",
       "19      < a class = ' hashtag-link ' href = ' / ho-chi...\n",
       "20      Mình nghe bạn bè giới thiệu nên đến đây uống t...\n",
       "21      Quán đồ ăn ngon . Không gan rộnh rãi thoáng má...\n",
       "22      Lâu rồi mình không ghé quán này , hôm bữa cũng...\n",
       "23      Quán dễ thương , nhạc hay , giá nước rất mềm n...\n",
       "24      Đối với mình món này dở tệ\\n+ quán ven đuờng h...\n",
       "25      Mình đi ăn vào hôm chủ nhật khá là đông ! ! Đế...\n",
       "26      Phục vụ chậm chạp . Giá trung bình một món là ...\n",
       "27      Trà sữa ngon , không gian thoáng , hũ đựng dễ ...\n",
       "28      Tối hôn qua mình mới đi ăn thử . Kem không quá...\n",
       "29      Quán bình dân nhưng trang trí rất dễ thương , ...\n",
       "                              ...                        \n",
       "2970    Mặc dù quán nằm trong hẻm nhưng cũng không khó...\n",
       "2971    Tàu hủ ngon cực luôn mà mở cửa hơi trễ 4h mới ...\n",
       "2972    Giá vé có 100k/ng kèm đồ uống , k gian thì tuy...\n",
       "2973    Ở đây hầu như món nào cũng ngon ! Giá cả lại r...\n",
       "2974    Tản bộ trên đường Mạc Đỉnh Chi vô tình mình th...\n",
       "2975    Mới đến ngày 10/3 xong ... bánh đăy cũng khá r...\n",
       "2976    combo kiu ra ngày càng ít nhất là combo siêu n...\n",
       "2977    Hôm nay quay lại cảm giác vẫn thế\\nMọi thứ thậ...\n",
       "2978    Quán nhỏ nhưng rất ấm cúng . Cô chủ thân thiện...\n",
       "2979    Quán này ăn từ rất lâu rồi , biết đến quán từ ...\n",
       "2980    Đi cùng trường có chuyến thực tế . Đến vina rấ...\n",
       "2981    Mình bị nghiện kem ở đây í : ' ) Có mấy cơ sở ...\n",
       "2982    Giữa tháng 4/2016 mình ăn ở đây , cẩn thận ko ...\n",
       "2983    Không biết là ở tất cả các chi nhánh hay chỉ m...\n",
       "2984    Đồ ăn tàm tạm mà lại đắt nữa .\\nĐợi cũng khá l...\n",
       "2985    Lần nào đi làm về cũng ghé mua 1 hộp thập cẩm ...\n",
       "2986    Mình có hay đi bộ ngang đây vào những ngày nắn...\n",
       "2987    Thấy quán mới gần nhà , lại được review khá tố...\n",
       "2988    Lần đầu tiên đến với quán ... . .\\nphải nói từ...\n",
       "2989    Mình nhận ship đồ về . Cơm dẻo kiểu cơm nếp , ...\n",
       "2990    Hôm rồi vào quán cùng người bạn . Mình gọi cơm...\n",
       "2991    Hitea là hệ thống lớn . Nước úông thì ngon , n...\n",
       "2992    Hôm qua tình cờ ghé quán và đúng lúc quán vừa ...\n",
       "2993    Mình ăn quán này từ hồi nhỏ . Lúc đó quán cũng...\n",
       "2994    Kimchi Kimchi này mình ăn bên Đinh Tiên Hoàng ...\n",
       "2995    Quán này đc cái mạng nhanh , không gian thoải ...\n",
       "2996    Hôm mình đi quán mới khai trương được 1 , 2 ng...\n",
       "2997    Đã tới đây 1 lần rồi , nhưng hơi thất vọng , H...\n",
       "2998    cả đám đi học về ghé quán ăn thử . cũng là ngư...\n",
       "2999    mình ko biết ở đây có gì mà đông dữ vậy , quán...\n",
       "Name: text, Length: 3000, dtype: object"
      ]
     },
     "execution_count": 113,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UJ0wUC8sm_aa",
    "outputId": "7da137ad-954d-473a-9b41-5aa803d632f4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [03:47, 13.19it/s]\n"
     ]
    }
   ],
   "source": [
    "for _, row in tqdm(test_df.iterrows()):\n",
    "    submission.loc[row.id] = predict2(row.text, model, model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ubrC3SpYohzX"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('test_result.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNN model: 0.853 in testset\n",
    "\n",
    "CNN model: 0.872 in testset\n",
    "\n",
    "Vote 2 model: 0.887 in testset"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment_4_Sentiment_Analysis_edited.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
